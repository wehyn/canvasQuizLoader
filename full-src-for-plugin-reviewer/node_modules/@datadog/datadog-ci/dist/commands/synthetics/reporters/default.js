"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.getTunnelReporter = exports.DefaultReporter = exports.getResultUrlSuffix = void 0;
const chalk_1 = __importDefault(require("chalk"));
const ora_1 = __importDefault(require("ora"));
const interfaces_1 = require("../interfaces");
const internal_1 = require("../utils/internal");
const public_1 = require("../utils/public");
const constants_1 = require("./constants");
// Step rendering
const renderStepDuration = (duration) => {
    const getColor = () => {
        if (duration > 10000) {
            return chalk_1.default.bold.red;
        }
        if (duration > 5000) {
            return chalk_1.default.bold.yellow;
        }
        return chalk_1.default.bold;
    };
    const color = getColor();
    return `${color(duration.toString())}ms`;
};
const renderStepIcon = (step) => {
    if (step.error) {
        return constants_1.ICONS.FAILED;
    }
    if (step.skipped) {
        return constants_1.ICONS.SKIPPED;
    }
    return constants_1.ICONS.SUCCESS;
};
const renderStep = (step) => {
    const duration = renderStepDuration(step.duration);
    const icon = renderStepIcon(step);
    const value = step.value ? `\n    ${chalk_1.default.dim(step.value)}` : '';
    const error = step.error ? `\n    ${chalk_1.default.red.dim(step.error)}` : '';
    return `    ${icon} | ${duration} - ${step.description}${value}${error}`;
};
const renderSkippedSteps = (steps) => {
    if (!steps.length) {
        return;
    }
    if (steps.length === 1) {
        return renderStep(steps[0]);
    }
    return `    ${constants_1.ICONS.SKIPPED} | ${steps.length} skipped steps`;
};
const renderApiError = (errorCode, errorMessage, color) => {
    if (errorCode === 'INCORRECT_ASSERTION') {
        try {
            const assertionsErrors = JSON.parse(errorMessage);
            const output = [`  - ${(0, public_1.pluralize)('Assertion', assertionsErrors.length)} failed:`];
            output.push(...assertionsErrors.map((error) => {
                const expected = chalk_1.default.underline(`${error.target}`);
                const actual = chalk_1.default.underline(`${error.actual}`);
                return `▶ ${error.type} ${public_1.readableOperation[error.operator]} ${expected}. Actual: ${actual}`;
            }));
            return color(output.join('\n    '));
        }
        catch (e) {
            // JSON parsing failed, do nothing to return the raw error
        }
    }
    return chalk_1.default.red(`    [${chalk_1.default.bold(errorCode)}] - ${chalk_1.default.dim(errorMessage)}`);
};
// Test execution rendering
const renderResultOutcome = (result, test, icon, color) => {
    if (result === null || result === void 0 ? void 0 : result.unhealthy) {
        const error = result.failure && result.failure.message !== 'Unknown error' ? result.failure.message : 'General Error';
        return [
            `  ${chalk_1.default.yellow(`${constants_1.ICONS.SKIPPED} | ${error}`)}`,
            `  ${chalk_1.default.yellow('We had an error during the execution of this test. The result will be ignored')}`,
        ].join('\n');
    }
    if (test.type === 'api') {
        const requestDescription = renderApiRequestDescription(test.subtype, test.config);
        if (result === null || result === void 0 ? void 0 : result.failure) {
            return [
                `  ${icon} ${color(requestDescription)}`,
                renderApiError(result.failure.code, result.failure.message, color),
            ].join('\n');
        }
        return `  ${icon} ${color(requestDescription)}`;
    }
    if (test.type === 'browser') {
        const lines = [];
        if (result === null || result === void 0 ? void 0 : result.failure) {
            lines.push(chalk_1.default.red(`    [${chalk_1.default.bold(result.failure.code)}] - ${chalk_1.default.dim(result.failure.message)}`));
        }
        // We render the step only if the test hasn't passed to avoid cluttering the output.
        if (result && !result.passed && 'stepDetails' in result) {
            const criticalFailedStepIndex = result.stepDetails.findIndex((s) => s.error && !s.allowFailure) + 1;
            lines.push(...result.stepDetails.slice(0, criticalFailedStepIndex).map(renderStep));
            const skippedStepDisplay = renderSkippedSteps(result.stepDetails.slice(criticalFailedStepIndex));
            if (skippedStepDisplay) {
                lines.push(skippedStepDisplay);
            }
        }
        return lines.join('\n');
    }
};
const renderApiRequestDescription = (subType, config) => {
    const { request, steps } = config;
    if (subType === 'dns') {
        const text = `Query for ${request.host}`;
        if (request.dnsServer) {
            return `${text} on server ${request.dnsServer}`;
        }
        return text;
    }
    if (subType === 'ssl' || subType === 'tcp') {
        return `Host: ${request.host}:${request.port}`;
    }
    if (subType === 'multi' && steps) {
        const stepsDescription = Object.entries(steps
            .map((step) => step.subtype)
            .reduce((counts, type) => {
            counts[type] = (counts[type] || 0) + 1;
            return counts;
        }, {}))
            .map(([type, count]) => `${count} ${type.toUpperCase()} test`)
            .join(', ');
        return `Multistep test containing ${stepsDescription}`;
    }
    if (subType === 'http') {
        return `${chalk_1.default.bold(request.method)} - ${request.url}`;
    }
    return `${chalk_1.default.bold(subType)} test`;
};
const renderExecutionResult = (test, execution, baseUrl, batchId) => {
    var _a, _b;
    const { executionRule, test: overriddenTest, resultId } = execution;
    const resultOutcome = (0, public_1.getResultOutcome)(execution);
    const [icon, setColor] = getResultIconAndColor(resultOutcome);
    const editedText = ((_a = execution.selectiveRerun) === null || _a === void 0 ? void 0 : _a.decision) === 'run' && execution.selectiveRerun.reason === 'edited'
        ? chalk_1.default.dim('(edited) ')
        : '';
    const executionRuleText = public_1.PASSED_RESULT_OUTCOMES.includes(resultOutcome)
        ? ''
        : `[${setColor(executionRule === interfaces_1.ExecutionRule.BLOCKING ? 'blocking' : 'non-blocking')}] `;
    const publicId = (0, internal_1.getPublicIdOrPlaceholder)(test);
    const testLabel = `${editedText}${executionRuleText}[${chalk_1.default.bold.dim(publicId)}] ${chalk_1.default.bold(test.name)}`;
    const resultIdentificationSuffix = getResultIdentificationSuffix(execution, setColor);
    const resultIdentification = `${icon} ${testLabel}${resultIdentificationSuffix}`;
    const outputLines = [resultIdentification];
    // Unhealthy test results don't have a duration or result URL
    if ((0, internal_1.isBaseResult)(execution) && !((_b = execution.result) === null || _b === void 0 ? void 0 : _b.unhealthy)) {
        const durationText = execution.duration ? ` Total duration: ${execution.duration} ms -` : '';
        const resultUrl = (0, public_1.getResultUrl)(baseUrl, test, resultId, batchId);
        const resultUrlStatus = (0, exports.getResultUrlSuffix)(execution);
        outputLines.push(`  •${durationText} View test run details:`);
        outputLines.push(`    ⎋ ${chalk_1.default.dim.cyan(resultUrl)}${resultUrlStatus}`);
    }
    if ((0, public_1.isResultSkippedBySelectiveRerun)(execution)) {
        const resultUrl = (0, public_1.getResultUrl)(baseUrl, test, resultId, batchId);
        outputLines.push(chalk_1.default.dim(`  ${setColor('◀')} Successful result from a ${setColor('previous')} CI batch:`));
        outputLines.push(`    ⎋ ${chalk_1.default.dim.cyan(resultUrl)}`);
    }
    else {
        const resultOutcomeText = renderResultOutcome(execution.result, overriddenTest || test, icon, setColor);
        if (resultOutcomeText) {
            outputLines.push(resultOutcomeText);
        }
    }
    return outputLines.join('\n');
};
const getResultIdentificationSuffix = (execution, setColor) => {
    if ((0, internal_1.isBaseResult)(execution)) {
        const { result, passed, retries, maxRetries, timedOut } = execution;
        const location = execution.location ? setColor(`location: ${chalk_1.default.bold(execution.location)}`) : '';
        const device = result && (0, public_1.isDeviceIdSet)(result) ? ` - ${setColor(`device: ${chalk_1.default.bold(result.device.id)}`)}` : '';
        const attempt = getAttemptSuffix(passed, retries, maxRetries, timedOut);
        return ` - ${location}${device}${attempt}`;
    }
    return '';
};
const getResultUrlSuffix = (execution) => {
    if ((0, internal_1.isBaseResult)(execution)) {
        const { retries, maxRetries, timedOut } = execution;
        const timedOutRetry = (0, internal_1.isTimedOutRetry)(retries, maxRetries, timedOut);
        if (timedOutRetry) {
            return ' (previous attempt)';
        }
        if (timedOut) {
            return ' (not yet received)';
        }
    }
    return '';
};
exports.getResultUrlSuffix = getResultUrlSuffix;
const getAttemptSuffix = (passed, retries, maxRetries, timedOut) => {
    const currentAttempt = retries + 1;
    const maxAttempts = maxRetries + 1;
    if (maxAttempts === 1) {
        // No need to talk about "attempts" if retries aren't configured.
        return '';
    }
    if (passed && retries === 0) {
        // No need to display anything if the test passed on the first attempt.
        return '';
    }
    const attempt = (current, max) => {
        if (!passed && current < max) {
            return chalk_1.default.dim(`attempt ${current} of ${max}, retrying…`);
        }
        return chalk_1.default.dim(`attempt ${current}, done`);
    };
    if ((0, internal_1.isTimedOutRetry)(retries, maxRetries, timedOut)) {
        // Current attempt is still that of the last received result, so we increment it to refer to the expected retry.
        return ` (${attempt(currentAttempt + 1, maxAttempts)})`;
    }
    return ` (${attempt(currentAttempt, maxAttempts)})`;
};
const getResultIconAndColor = (resultOutcome) => {
    if (public_1.PASSED_RESULT_OUTCOMES.includes(resultOutcome)) {
        return [constants_1.ICONS.SUCCESS, chalk_1.default.bold.green];
    }
    if (resultOutcome === "failed-non-blocking" /* ResultOutcome.FailedNonBlocking */) {
        return [constants_1.ICONS.FAILED_NON_BLOCKING, chalk_1.default.bold.yellow];
    }
    return [constants_1.ICONS.FAILED, chalk_1.default.bold.red];
};
class DefaultReporter {
    constructor({ context }) {
        this.context = context;
        this.write = context.stdout.write.bind(context.stdout);
    }
    error(error) {
        this.removeSpinner();
        this.write(error);
    }
    initErrors(errors) {
        this.removeSpinner();
        this.write(errors.join('\n') + '\n\n');
    }
    log(log) {
        this.removeSpinner();
        this.write(log);
    }
    reportStart(timings) {
        this.totalDuration = Date.now() - timings.startTime;
        this.removeSpinner();
        this.write(['', chalk_1.default.bold.cyan('=== REPORT ==='), `Took ${chalk_1.default.bold(this.totalDuration).toString()}ms`, '\n'].join('\n'));
    }
    resultEnd(result, baseUrl, batchId) {
        var _a;
        // Stop the spinner so it doesn't show multiple times in a burst of received results.
        (_a = this.testWaitSpinner) === null || _a === void 0 ? void 0 : _a.stop();
        this.write(renderExecutionResult(result.test, result, baseUrl, batchId) + '\n\n');
    }
    resultReceived(result) {
        return;
    }
    runEnd(summary, baseUrl, orgSettings) {
        const { bold: b, gray, green, red, yellow } = chalk_1.default;
        const lines = [];
        const runSummary = [];
        if (summary.previouslyPassed) {
            runSummary.push(green(`${b(summary.passed)} passed (${b(summary.previouslyPassed)} in a previous CI batch)`));
        }
        else {
            runSummary.push(green(`${b(summary.passed)} passed`));
        }
        runSummary.push(red(`${b(summary.failed)} failed`));
        if (summary.failedNonBlocking) {
            runSummary.push(yellow(`${b(summary.failedNonBlocking)} failed (non-blocking)`));
        }
        if (summary.skipped) {
            runSummary.push(`${b(summary.skipped)} skipped`);
        }
        if (summary.testsNotFound.size > 0) {
            const testsNotFoundListStr = gray(`(${[...summary.testsNotFound].join(', ')})`);
            lines.push(`${yellow(`${b(summary.testsNotFound.size)} ${(0, public_1.pluralize)('test', summary.testsNotFound.size)} not found`)} ${testsNotFoundListStr}`);
        }
        const extraInfo = [];
        if (summary.timedOut) {
            extraInfo.push(yellow(`${b(summary.timedOut)} timed out`));
        }
        if (summary.criticalErrors) {
            extraInfo.push(red(`${b(summary.criticalErrors)} critical errors`));
        }
        const extraInfoStr = extraInfo.length ? ' (' + extraInfo.join(', ') + ')' : '';
        if (summary.batchId) {
            const batchUrl = (0, public_1.getBatchUrl)(baseUrl, summary.batchId);
            lines.push('View full summary in Datadog: ' + chalk_1.default.dim.cyan(batchUrl));
        }
        lines.push(`\n${b('Continuous Testing Summary:')}`);
        lines.push(`• Test Results: ${runSummary.join(', ')}${extraInfoStr}`);
        if (orgSettings && orgSettings.onDemandConcurrencyCap > 0) {
            lines.push(`• Max parallelization configured: ${orgSettings.onDemandConcurrencyCap} test${orgSettings.onDemandConcurrencyCap > 1 ? 's' : ''} running at the same time`);
        }
        if (summary.previouslyPassed) {
            lines.push(`• Selective rerun: ran ${summary.expected - summary.previouslyPassed} out of ${summary.expected} tests`);
        }
        if (this.totalDuration) {
            const min = Math.floor(this.totalDuration / (60 * 1000));
            const sec = Math.round((this.totalDuration % (60 * 1000)) / 1000);
            lines.push(`• Total Duration:${min > 0 ? ' ' + min.toString() + 'm' : ''}${sec > 0 ? ' ' + sec.toString() + 's' : ''}`);
        }
        if (orgSettings && orgSettings.onDemandConcurrencyCap > 0) {
            lines.push(`\nIncrease your parallelization to reduce the test batch duration: ${chalk_1.default.dim.cyan(baseUrl + 'synthetics/settings/continuous-testing')}\n`);
        }
        this.write(lines.join('\n') + '\n');
    }
    testsWait(tests, baseUrl, batchId, skippedCount) {
        const testsList = tests.map((t) => (0, internal_1.getPublicIdOrPlaceholder)(t));
        if (testsList.length > 10) {
            testsList.splice(10);
            testsList.push('…');
        }
        const testsDisplay = chalk_1.default.gray(`(${testsList.join(', ')})`);
        const testCountText = (0, public_1.pluralize)('test', tests.length);
        const skippingCountText = skippedCount ? ` (skipping ${chalk_1.default.bold.cyan(skippedCount)} already successful)` : '';
        const text = tests.length > 0
            ? `Waiting for ${chalk_1.default.bold.cyan(tests.length)} ${testCountText}${skippingCountText} ${testsDisplay}…\n`
            : 'Waiting for the batch to end…\n';
        if (this.testWaitSpinner) {
            // Only refresh the spinner when the text changes.
            // The refreshed text will be persisted in the CI logs.
            if (this.testWaitSpinner.text !== text) {
                this.testWaitSpinner.text = text;
                this.testWaitSpinner.start();
            }
            return;
        }
        const batchUrl = (0, public_1.getBatchUrl)(baseUrl, batchId);
        this.write(`View pending summary in Datadog: ${chalk_1.default.dim.cyan(batchUrl)}\n\n`);
        this.testWaitSpinner = (0, ora_1.default)({
            stream: this.context.stdout,
            prefixText: '\n',
            text,
        });
        this.testWaitSpinner.start();
    }
    testTrigger(test, testId, executionRule, testOverrides) {
        const idDisplay = `[${chalk_1.default.bold.dim(testId)}]`;
        const getMessage = () => {
            if (executionRule === interfaces_1.ExecutionRule.SKIPPED) {
                // Test is either skipped from datadog-ci config or from test config
                const isSkippedByCIConfig = testOverrides.executionRule === interfaces_1.ExecutionRule.SKIPPED;
                if (isSkippedByCIConfig) {
                    return `Skipped test "${chalk_1.default.yellow.dim(test.name)}"`;
                }
                else {
                    return `Skipped test "${chalk_1.default.yellow.dim(test.name)}" because of execution rule configuration in Datadog`;
                }
            }
            if (executionRule === interfaces_1.ExecutionRule.NON_BLOCKING) {
                return `Found test "${chalk_1.default.green.bold(test.name)}" (non-blocking)`;
            }
            return `Found test "${chalk_1.default.green.bold(test.name)}"`;
        };
        const getTestOverridesPart = () => {
            const nbConfigsOverridden = (0, public_1.getTestOverridesCount)(testOverrides);
            if (nbConfigsOverridden === 0 || executionRule === interfaces_1.ExecutionRule.SKIPPED) {
                return '';
            }
            return ' ' + chalk_1.default.gray(`(${nbConfigsOverridden} test ${(0, public_1.pluralize)('override', nbConfigsOverridden)})`);
        };
        this.write(`${idDisplay} ${getMessage()}${getTestOverridesPart()}\n`);
    }
    testWait(test) {
        return;
    }
    removeSpinner() {
        var _a;
        (_a = this.testWaitSpinner) === null || _a === void 0 ? void 0 : _a.stop();
        delete this.testWaitSpinner;
    }
}
exports.DefaultReporter = DefaultReporter;
const getTunnelReporter = (reporter) => ({
    log: (message) => reporter.log(`[${chalk_1.default.bold.blue('Tunnel')}] ${message}\n`),
    error: (message) => reporter.error(`[${chalk_1.default.bold.yellow('Tunnel')}] ${message}\n`),
    warn: (message) => reporter.error(`[${chalk_1.default.bold.red('Tunnel')}] ${message}\n`),
});
exports.getTunnelReporter = getTunnelReporter;
//# sourceMappingURL=default.js.map